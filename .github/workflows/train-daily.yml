name: Train - Daily

on:
  schedule:
    - cron: '15 2 * * *'
  workflow_dispatch:

concurrency:
  group: train-daily
  cancel-in-progress: false

jobs:
  train-stack-predict:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install minimal dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas>=2.0.0
          pip install numpy scipy scikit-learn
          pip install lightgbm xgboost joblib optuna
          pip install requests tqdm
          pip install typeguard pyarrow
          pip install feast[sqlite]
          pip install "protobuf>=3.20,<4.0" --force-reinstall

      - name: Ensure features exist (fallback rebuild if missing)
        env:
          OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
        run: |
          if [ ! -f Data/feature_store/karachi_daily_features.parquet ]; then 
            echo 'Features parquet missing. Rebuilding features...';
            python Data_Collection/data_fetch.py;
            
            # Verify the parquet file was actually created
            if [ ! -f Data/feature_store/karachi_daily_features.parquet ]; then
              echo 'ERROR: data_fetch.py failed to create parquet file!';
              echo 'Checking if CSV was created instead...';
              if [ -f Data/feature_store/karachi_daily_features.csv ]; then
                echo 'CSV exists but parquet missing. This indicates parquet creation failed.';
                ls -la Data/feature_store/;
              else
                echo 'Neither CSV nor parquet was created. data_fetch.py completely failed.';
              fi
              exit 1;
            fi
            echo 'Parquet file successfully created.';
          else
            echo 'Found existing features parquet.';
          fi

      - name: Train LightGBM
        working-directory: Models
        run: python train_lightgbm.py --holdout_days 90 --tune --tune_trials 100

      - name: Train HGBR
        working-directory: Models
        run: python train_hgbr.py --holdout_days 90 --tune --tune_trials 100

      - name: Train Linear
        working-directory: Models
        run: python train_linear.py --holdout_days 90

      - name: Train RandomForest
        working-directory: Models
        run: python train_rf.py --holdout_days 90

      - name: Stack and calibrate
        working-directory: Models
        run: python stacking_linear_lightgbm.py --holdout_days 90 --constrain_nonneg --sum_to_one --calibrate

      - name: Upload summaries and models
        uses: actions/upload-artifact@v4
        with:
          name: train-artifacts-${{ github.run_id }}
          path: |
            Models/EDA/lightgbm_output/summary.json
            Models/EDA/hgbr_output/summary.json
            Models/EDA/linear_output/summary.json
            Models/EDA/rf_output/summary.json
            Models/EDA/blend_output/summary.json
            Models/Models/registry/*_preds.csv
            Models/Models/registry/blend_weights_*.json
          retention-days: 14


